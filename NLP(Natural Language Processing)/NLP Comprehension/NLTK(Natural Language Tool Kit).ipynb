{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T03:52:06.775531Z",
     "start_time": "2021-08-31T03:51:37.240654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\saite\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\saite\\anaconda3\\lib\\site-packages (from nltk) (4.50.2)\n",
      "Requirement already satisfied: click in c:\\users\\saite\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\users\\saite\\anaconda3\\lib\\site-packages (from nltk) (2020.10.15)\n",
      "Requirement already satisfied: joblib in c:\\users\\saite\\anaconda3\\lib\\site-packages (from nltk) (0.17.0)\n"
     ]
    }
   ],
   "source": [
    "#Install the libraries\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T02:38:08.862260Z",
     "start_time": "2021-09-02T02:37:31.742068Z"
    }
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import nltk\n",
    "\n",
    "#Download the model\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do sentence tokonization and word tokonization we use above downloaded model 'punkt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T02:38:15.122672Z",
     "start_time": "2021-09-02T02:38:15.111671Z"
    }
   },
   "outputs": [],
   "source": [
    "data = \"India (Hindi: Bhārat), officially the Republic of India, is a country in South Asia. It is the seventh-largest country by area, the second-most populous country, and the most populous democracy in the world. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west; China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T02:38:21.548745Z",
     "start_time": "2021-09-02T02:38:19.134142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['India (Hindi: Bhārat), officially the Republic of India, is a country in South Asia.',\n",
       " 'It is the seventh-largest country by area, the second-most populous country, and the most populous democracy in the world.',\n",
       " 'Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west; China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east.',\n",
       " 'In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentense tokenization\n",
    "\n",
    "nltk.sent_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T02:38:24.716782Z",
     "start_time": "2021-09-02T02:38:24.688780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['India',\n",
       " '(',\n",
       " 'Hindi',\n",
       " ':',\n",
       " 'Bhārat',\n",
       " ')',\n",
       " ',',\n",
       " 'officially',\n",
       " 'the',\n",
       " 'Republic',\n",
       " 'of',\n",
       " 'India',\n",
       " ',',\n",
       " 'is',\n",
       " 'a',\n",
       " 'country',\n",
       " 'in',\n",
       " 'South',\n",
       " 'Asia',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'the',\n",
       " 'seventh-largest',\n",
       " 'country',\n",
       " 'by',\n",
       " 'area',\n",
       " ',',\n",
       " 'the',\n",
       " 'second-most',\n",
       " 'populous',\n",
       " 'country',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'most',\n",
       " 'populous',\n",
       " 'democracy',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'Bounded',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Indian',\n",
       " 'Ocean',\n",
       " 'on',\n",
       " 'the',\n",
       " 'south',\n",
       " ',',\n",
       " 'the',\n",
       " 'Arabian',\n",
       " 'Sea',\n",
       " 'on',\n",
       " 'the',\n",
       " 'southwest',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Bay',\n",
       " 'of',\n",
       " 'Bengal',\n",
       " 'on',\n",
       " 'the',\n",
       " 'southeast',\n",
       " ',',\n",
       " 'it',\n",
       " 'shares',\n",
       " 'land',\n",
       " 'borders',\n",
       " 'with',\n",
       " 'Pakistan',\n",
       " 'to',\n",
       " 'the',\n",
       " 'west',\n",
       " ';',\n",
       " 'China',\n",
       " ',',\n",
       " 'Nepal',\n",
       " ',',\n",
       " 'and',\n",
       " 'Bhutan',\n",
       " 'to',\n",
       " 'the',\n",
       " 'north',\n",
       " ';',\n",
       " 'and',\n",
       " 'Bangladesh',\n",
       " 'and',\n",
       " 'Myanmar',\n",
       " 'to',\n",
       " 'the',\n",
       " 'east',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'Indian',\n",
       " 'Ocean',\n",
       " ',',\n",
       " 'India',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'vicinity',\n",
       " 'of',\n",
       " 'Sri',\n",
       " 'Lanka',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Maldives',\n",
       " ';',\n",
       " 'its',\n",
       " 'Andaman',\n",
       " 'and',\n",
       " 'Nicobar',\n",
       " 'Islands',\n",
       " 'share',\n",
       " 'a',\n",
       " 'maritime',\n",
       " 'border',\n",
       " 'with',\n",
       " 'Thailand',\n",
       " 'and',\n",
       " 'Indonesia',\n",
       " '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word tokenization\n",
    "\n",
    "nltk.word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T04:16:28.479746Z",
     "start_time": "2021-08-31T04:16:27.623004Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\saite\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download below model for parts of speech recognition\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T02:38:37.972317Z",
     "start_time": "2021-09-02T02:38:37.416180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('we', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('see', 'VB'),\n",
       " ('an', 'DT'),\n",
       " ('example', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('pos', 'NN'),\n",
       " ('tagging', 'NN')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'we will see an example of pos tagging'\n",
    "word_token = nltk.word_tokenize(data)\n",
    "\n",
    "#Parts of speech(POS) word\n",
    "\n",
    "pos = nltk.pos_tag(word_token)\n",
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T04:19:52.357543Z",
     "start_time": "2021-08-31T04:19:52.348540Z"
    }
   },
   "source": [
    "link for all abb for pos - https://www.guru99.com/pos-tagging-chunking-nltk.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a function that takes a string and return total sentences count, total word counts, and all the verbs in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T02:38:41.496309Z",
     "start_time": "2021-09-02T02:38:41.442711Z"
    }
   },
   "outputs": [],
   "source": [
    "def counts(data):\n",
    "    print('Number of sentences - ', str(len(nltk.sent_tokenize(data))))\n",
    "    print('Total word counts - ', str(len(nltk.word_tokenize(data))))\n",
    "    word_token = nltk.word_tokenize(data)\n",
    "    print('Verbs in a sentence - ', [i for i in nltk.pos_tag(word_token) if 'VB' in i[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T02:38:45.271708Z",
     "start_time": "2021-09-02T02:38:45.241708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences -  5\n",
      "Total word counts -  154\n",
      "Verbs in a sentence -  [('captained', 'VBD'), ('made', 'VBD'), ('having', 'VBG'), ('played', 'VBN'), ('established', 'VBD'), ('was', 'VBD'), ('won', 'VBD'), ('made', 'VBD'), ('shrugged', 'VBD'), ('reached', 'VBD'), ('[', 'VBD'), ('found', 'VBD'), ('winning', 'VBG')]\n"
     ]
    }
   ],
   "source": [
    "data = data = \"\"\"Kohli captained India Under-19s to victory at the 2008 Under-19 World Cup in Malaysia. After a few months later, he made his ODI debut for India against Sri Lanka at the age of 19. Initially having played as a reserve batsman in the Indian team, he soon established himself as a regular in the ODI middle-order and was part of the squad that won the 2011 World Cup. He made his Test debut in 2011 and shrugged off the tag of \"ODI specialist\" by 2013 with Test hundreds in Australia and South Africa.[3] Having reached the number one spot in the ICC rankings for ODI batsmen for the first time in 2013,[4] Kohli also found success in the Twenty20 format, winning the Man of the Tournament twice at the ICC World Twenty20 (in 2014 and 2016)\"\"\"\n",
    "counts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T02:40:17.106694Z",
     "start_time": "2021-09-02T02:40:16.014757Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\saite\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To remove unimportant words and reprated words like prepositions from sentences we use 'stopwords'\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T02:42:25.250457Z",
     "start_time": "2021-09-02T02:42:25.212429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the stopwords \n",
    "#List of words are called as corpus in english\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#load the stopwords, need to mention on which language we need to work on\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "#Below printed list shows the words which are not much importance in a english paragraph, sentence etc. \n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T03:01:01.297434Z",
     "start_time": "2021-09-02T03:01:01.287433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'india ( hindi : bhārat ) , officially republic india , country south asia . seventh-largest country area , second-most populous country , populous democracy world . bounded indian ocean south , arabian sea southwest , bay bengal southeast , shares land borders pakistan west ; china , nepal , bhutan north ; bangladesh myanmar east . indian ocean , india vicinity sri lanka maldives ; andaman nicobar islands share maritime border thailand indonesia .'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"India (Hindi: Bhārat), officially the Republic of India, is a country in South Asia. It is the seventh-largest country by area, the second-most populous country, and the most populous democracy in the world. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west; China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.\"\n",
    "\n",
    "#word tokenization\n",
    "#remove the stopwords\n",
    "#join the words and make a sentence\n",
    "\n",
    "def remove_stopwords(data):\n",
    "    joined = []\n",
    "    word_token = nltk.word_tokenize(data.lower())\n",
    "    for i in word_token:\n",
    "        if i not in stopwords:\n",
    "            joined.append(i)\n",
    "    return ' '.join(joined)\n",
    "\n",
    "remove_stopwords(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T03:01:56.255455Z",
     "start_time": "2021-09-02T03:01:56.250450Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing punctuations from sentence\n",
    "import string\n",
    "\n",
    "punct = string.punctuation\n",
    "punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T03:04:27.843580Z",
     "start_time": "2021-09-02T03:04:27.836566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "india hindi bhārat officially republic india country south asia seventh-largest country area second-most populous country populous democracy world bounded indian ocean south arabian sea southwest bay bengal southeast shares land borders pakistan west china nepal bhutan north bangladesh myanmar east indian ocean india vicinity sri lanka maldives andaman nicobar islands share maritime border thailand indonesia\n",
      "['india', 'hindi', 'bhārat', 'officially', 'republic', 'india', 'country', 'south', 'asia', 'seventh-largest', 'country', 'area', 'second-most', 'populous', 'country', 'populous', 'democracy', 'world', 'bounded', 'indian', 'ocean', 'south', 'arabian', 'sea', 'southwest', 'bay', 'bengal', 'southeast', 'shares', 'land', 'borders', 'pakistan', 'west', 'china', 'nepal', 'bhutan', 'north', 'bangladesh', 'myanmar', 'east', 'indian', 'ocean', 'india', 'vicinity', 'sri', 'lanka', 'maldives', 'andaman', 'nicobar', 'islands', 'share', 'maritime', 'border', 'thailand', 'indonesia']\n"
     ]
    }
   ],
   "source": [
    "#Removing punctuations from sentence\n",
    "def remove_stopwords(data):\n",
    "    joined = []\n",
    "    word_token = nltk.word_tokenize(data.lower())\n",
    "    for i in word_token:\n",
    "        if (i not in stopwords) and (i not in punct):\n",
    "            joined.append(i)\n",
    "    return ' '.join(joined), joined\n",
    "\n",
    "sentence, list_of_words=remove_stopwords(data)\n",
    "\n",
    "print(sentence)\n",
    "print(list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming or Lemmatization - Converting the word in its root/ base form(i.e.. changing verbs to V1 form)\n",
    "\n",
    "Stemming -  Bringing the word to its stem form\n",
    "            drawback - the resultant word may or maynot have a meaning\n",
    "            \n",
    "            Ex - history historical\n",
    "                it changes history- history\n",
    "                it changes historical - histori(Where meaning is not maintained)\n",
    "                \n",
    "                \n",
    "Lemmatization - Bringing the word to its root form\n",
    "                the resultant word will have a meaning\n",
    "            \n",
    "                Ex - history historical\n",
    "                it changes history- history\n",
    "                it changes historical - history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n",
    "finally\n",
    "final        --  fina\n",
    "finalised\n",
    "\n",
    "#Lemmatization\n",
    "finally\n",
    "final        --  final\n",
    "finalised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use only stemming where the meaning of the word is not important and it's frequency is important\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T03:25:32.067948Z",
     "start_time": "2021-09-02T03:25:32.049950Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "\n",
    "lancaster = LancasterStemmer() #only english\n",
    "porter = PorterStemmer() #only english\n",
    "snowball = SnowballStemmer('english') #multiple languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T03:29:22.943811Z",
     "start_time": "2021-09-02T03:29:22.920810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "porter stemmer\n",
      "hobbi\n",
      "hobbi\n",
      "comput\n",
      "comput\n",
      "-------------------------------\n",
      "lancaster stemmer\n",
      "hobby\n",
      "hobby\n",
      "comput\n",
      "comput\n",
      "-------------------------------\n",
      "snowball stemmer\n",
      "hobbi\n",
      "hobbi\n",
      "comput\n",
      "comput\n"
     ]
    }
   ],
   "source": [
    "print('porter stemmer')\n",
    "print(porter.stem('hobby'))\n",
    "print(porter.stem('hobbies'))\n",
    "print(porter.stem('computer'))\n",
    "print(porter.stem('computation'))\n",
    "print('-------------------------------')\n",
    "print('lancaster stemmer')\n",
    "print(lancaster.stem('hobby'))\n",
    "print(lancaster.stem('hobbies'))\n",
    "print(lancaster.stem('computer'))\n",
    "print(lancaster.stem('computation'))\n",
    "print('-------------------------------')\n",
    "print('snowball stemmer')\n",
    "print(snowball.stem('hobby'))\n",
    "print(snowball.stem('hobbies'))\n",
    "print(snowball.stem('computer'))\n",
    "print(snowball.stem('computation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T03:35:48.314413Z",
     "start_time": "2021-09-02T03:35:48.292411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i wa go to the offic on my bike when i saw a car pass by hit the tree\n",
      "i was going to the off on my bik when i saw a car pass by hit the tre\n",
      "i was go to the offic on my bike when i saw a car pass by hit the tree\n"
     ]
    }
   ],
   "source": [
    "sent = 'i was going to the office on my bike when i saw a car passing by hit the tree'\n",
    "def stemmer(stemmer, data):\n",
    "    final = []\n",
    "    for i in nltk.word_tokenize(data):\n",
    "        final.append(stemmer.stem(i))\n",
    "    return ' '.join(final)\n",
    "\n",
    "print(stemmer(porter, sent))\n",
    "print(stemmer(lancaster, sent))\n",
    "print(stemmer(snowball, sent))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T03:33:36.092115Z",
     "start_time": "2021-09-02T03:33:36.084127Z"
    }
   },
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T03:41:48.770962Z",
     "start_time": "2021-09-02T03:41:32.252395Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\saite\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download the model - it is a model not hardcoded \n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T03:48:30.593297Z",
     "start_time": "2021-09-02T03:48:30.586294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "go\n",
      "go\n"
     ]
    }
   ],
   "source": [
    "#import for lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "print(lemma.lemmatize('gone', pos = 'v'))\n",
    "print(lemma.lemmatize('goes', pos = 'v'))\n",
    "print(lemma.lemmatize('going', pos = 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T03:58:48.949611Z",
     "start_time": "2021-09-02T03:58:48.927605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go office bike saw car pass hit tree'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'i was going to the office on my bike when i saw a car passing by hit the tree'\n",
    "\n",
    "#Word tokenization\n",
    "#Clean - remove stopwords and punctuation\n",
    "#Root form\n",
    "#Convert back to sent\n",
    "\n",
    "def root_form(data):\n",
    "    final = []\n",
    "    for i in nltk.word_tokenize(data.lower()):\n",
    "        if (i not in stopwords) and (i not in punct):\n",
    "            final.append(lemma.lemmatize(i, pos = 'v'))\n",
    "    return ' '.join(final)\n",
    "\n",
    "root_form(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T03:54:27.643789Z",
     "start_time": "2021-09-02T03:54:27.631790Z"
    }
   },
   "source": [
    "#Pipeline\n",
    "\n",
    "unclean text data ---> lower -----> word tokenization\n",
    "----> remove stop words ----> punctation ---> root ----> clean data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Topic\n",
    "NER (Named entity recognition)\n",
    "\n",
    "We try to group entities like people, places, countries, thing etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T04:04:34.879132Z",
     "start_time": "2021-09-02T04:03:55.715384Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\saite\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\saite\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download the libraries\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T04:07:49.295704Z",
     "start_time": "2021-09-02T04:07:49.269702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE India/NNP)\n",
      "  ,/,\n",
      "  officially/RB\n",
      "  the/DT\n",
      "  republic/NN\n",
      "  of/IN\n",
      "  (GPE India/NNP)\n",
      "  ,/,\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  country/NN\n",
      "  in/IN\n",
      "  (GPE South/NNP Asia/NNP))\n"
     ]
    }
   ],
   "source": [
    "sent = 'India, officially the republic of India, is a country in South Asia'\n",
    "\n",
    "#Follow the pipeline\n",
    "words = nltk.word_tokenize(sent) #Never make our data to lowerCase in name entity recognition\n",
    "pos_tag = nltk.pos_tag(words)\n",
    "named_entity = nltk.ne_chunk(pos_tag)\n",
    "print(named_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-02T04:18:11.208393Z",
     "start_time": "2021-09-02T04:18:11.190388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Frequency distributor\n",
    "from nltk import FreqDist\n",
    "\n",
    "freq = FreqDist(nltk.word_tokenize(sent.lower()))\n",
    "freq['in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
